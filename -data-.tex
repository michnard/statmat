\subsection{Test per la verifica di ipotesi}

La procedura di test per la verifica di ipotesi che descriveremo a breve cerca di fornire una soluzione ai seguenti problemi:
\begin{enumerate}
\item Determinare quanto un'ipotesi è realistica, verosimile, compatibile con l'informazione empirica a disposizione.
\item Trovare un ragionamento oggettivo (matematico) per inferire dall'informazione disponibile (ovvero il contenuto di un campione) circa la veridicità dell'ipotesi formulata.
\item Misurare in qualche modo questa ''vicinanza'' tra ipotesi e realtà.
\end{enumerate}
Useremo statistiche pivot in ambito parametrico: la distribuzione da cui proviene il campione casuale $(X_1,...,X_n)$ è nota a meno di uno o più parametri.\\
Di seguito si può vedere una descrizione generale della situazione che si riproporrà per tutta questa sezione:\\
\\
$X \sim F_X(\underline{x},\theta)$, $\theta \in \Theta$, $(X_1,...,X_n)$ iid. Le nostre due ipotesi saranno della forma:
$$\bigg \{
\begin{array}{rl}
H_0: & \theta \in \Theta_0 \\
H_1: & \theta \in \Theta_1 \\
\end{array}
$$
con $\Theta_0 \cup \Theta_1 = \Theta$.\\
\\
Chiameremo $H_0$ \textit{ipotesi nulla} e $H_1$ \textit{ipotesi alternativa}. Di solito $H_0$ rappresenta la conoscenza pregressa, la supposizione vera fino a prova contraria. Al contrario, $H_1$ è l'ipotesi di lavoro, quella su cui ripieghiamo nel momento in cui il nostro test risulta in contraddizione con $H_0$.\\
Il test si riduce a una \textit{regola di decisione} in merito a $H_0$ e $H_1$ sulla base del campione casuale $(X_1,...,X_n)$ da $X \sim F_X (x;\theta)$. La decisione può chiaramente essere corretta, ma anche errata, poiché il campione costituisce un'informazione non completa. Risulta quindi necessario formulare delle \textit{conslusioni in probabilità}, ovvero associare alla nostra conclusione la probabilità che questa sia corretta, cercando ovviamente di massimizzarla.\\
Possiamo riassumere le varie possibilità in questa tabella:
\\
\\
\begin{tabular}{c|c|c}
 & $H_0$ è vera & $H_0$ è falsa \\ 
\hline 
Rifiuto $H_0$ & errore di I specie & nessun errore \\ 
\hline 
Non rifiuto $H_0$ & nessun errore & errore di II specie \\ 
\end{tabular} 
\\
\\
INSERIRE DISEGNO\\
\\
\noindent \textbf{Esempio} Lancio di una moneta onesta. Consideriamo il campione casuale $(X_1,...,X_n)$ e il numero di teste $S_n = \sum_{i=1}^n X_i$. Vorremmo stimare la probabilità che esca testa con la media campionaria $\overline{X}_n$. In questo caso potremmo avere:
\\
$$\bigg \{
\begin{array}{rl}
H_0: & p=1/2 \\
H_1: & p \neq 1/2 \\
\end{array}
$$
\\
La regola di decisione consiste quindi nel rifiutare $H_0$ se $(X_1,...,X_n) \in C$ e invece rifiutare $H_0$ se $(X_1,...,X_n) \in C^c$. Ci piacerebbe trovare una regola di decisione che permetta di minimizzare la probabilità di commettere errori di I o II tipo. Purtroppo questo non è possibile, per la natura stessa della relazione che corre tra gli errori di I e II tipo. Di seguito un esempio che ci dà un'idea del perché:\\

\noindent \textbf{Esempio} Consideriamo un campione casuale $(X_1,...,X_n)$ da $N(\mu,\sigma^2)$ con $\sigma^2$ noto. Supponiamo che le nostre due ipotesi siano:
\\
$$\bigg \{
\begin{array}{lcr}
H_0: & \mu=\mu_0 & \text{ovvero } N(\mu=\mu_0,\sigma^2) \\
H_1: & \mu=\mu_1 & \text{ovvero } N(\mu=\mu_1,\sigma^2) \\
\end{array}
$$
con $\mu_1 > \mu_0$.\\
\\
INSERIRE DISEGNO\\
\\
Consideriamo $\alpha:= P(\text{rifiutare } H_0 \mid H_0 \text{ vera}) = P(\text{il nostro campione appartiene a C} \mid H_0 \text{ vera}) = P(\text{il nostro campione è } \leq c) = P(\text{commettere un errore di I tipo})$ e $\beta:= P(\text{non rifiutare } H_0 \mid H_0 \text{ falsa}) = P(\text{il nostro campione appartiene a } C^c \mid H_0 \text{ falsa}) = P(\text{il nostro campione è } \geq c) = P(\text{commettere un errore di II tipo})$. 
(Nota: $\alpha$ è detto \emph{livello di significatività del test})\\
È evidente che non è possibile annullare contemporaneamente sia $\alpha$ che $\beta$.\\
La procedura si divide quindi in due passi: il primo consiste nel \textbf{fissare} $\alpha$, il secondo nell'individuare la regola di decisione che minimizza $\beta$, in modo da trovare un test \textit{ottimo}.\\
\\
\\
%%%%LEZIONE 5 APRILE%%%%
\\
In generale una statistica test si può descrivere come di seguito:\\
$$\bigg \{
\begin{array}{rl}
H_0: & \theta \in \Theta_0 \\
H_1: & \theta \in \Theta_1 \\
\end{array}
$$
\\
dove $\Theta$ è lo spazio dei possibili parametri della distribuzione e $\Theta = \Theta_0 \cup \Theta_1$.\\
Quello che vogliamo trovare è la regola di partizionamento che divida lo spazio dei campioni $C$ in $C_0$ e $C_1$ in funzione di $\alpha$ (deciso da noi). Per farlo imponiamo la condizione $\alpha = P(\underline{x} \in C \mid \theta \in \Theta_0)$. Vediamo ora un esempio con il lancio di una moneta:\\
\\
\noindent \textbf{Esempio} Consideriamo il campione casuale $(X_1,...,X_n)$ dove $X_i = 0$ con probabilità $p$ e $X_i = 1$ con probabilità $1-p$. Facciamo le nostre ipotesi:\\
$$\bigg \{
\begin{array}{rl}
H_0: & p \leq 1/2 \\
H_1: & p > 1/2 \\
\end{array}
$$
\\
Prediamo ora come regola di decisione $\frac{S}{n}=\frac{\sum X_i}{n}$. Deciso un $\alpha$ a nostra discrezione, imponiamo l'equazione in $k$:
$$ \alpha = P(S>k \mid p \leq 1/2) \; (= P(S>k \mid H_0 \text{ vera}))$$
A questo punto risolvendo l'equazione troveremo il $k$ per il quale rifiuteremo $H_0$ se $S>k$.\\
\\
\noindent \textbf{Esempio} Sia $(X_1,...,X_n)$ un campione casuale con $X_i \sim b(1,p)$ e sia\\
$$\bigg \{
\begin{array}{rl}
H_0: & p=p_0 \\
H_1: & p<p_0 \\
\end{array}
$$
\\
Sulla base dell'informazione circa $p$ contenuta in $(X_1,...,X_n)$ vogliamo sottoporre a verifica il sistema di ipotesi in questione. Procediamo in questo ordine:\\
\begin{enumerate}
\item [(a)] Prendiamo $S:=\sum X_i \sim b(n,p)$, che è di fatto il numero di successi. Sotto $H_0$ abbiamo che $S \sim b(n,p_0)$.
\item [(b)] Scegliamo una regola di decisione (usando anche la distribuzione -nota- di $S$ sotto $H_0$). Ovvero, individuiamo la \textit{regione di rifiuto del test}. A questo punto vorremo rifiutare $H_0$ a favore di $H_1$ quando $S \leq k$, dove $k$ è l'incognita che troveremo nel punto (c).
\item [(c)] Scelto il nostro $\alpha$, si ha che il valore di $k$ deve essere tale per cui 
			$$\alpha = P(S \leq k \mid p=p_0) = \displaystyle \sum_{s=0}^k \binom{n}{s} p_0^s (1-p_0)^{n-s}$$
A questo punto, essendo $\alpha$ fissato, abbiamo un'equazione in $k$ che risolta ci restituisce il suo valore.
\end{enumerate}
\textbf{Esempio particolare} Nella situazione generale sopra descritta prendiamo un caso particolare con $n=20$ e $p_0=0,7$. Decidiamo $\alpha = 0.15$. L'equazione diventa: $0,15 = \sum_{s=0}^k \binom{20}{s} 0,7^s 0,3^{20-s}$. Osserviamo che il valore di $P(S \leq k \mid p=0,7)$ per $k=11$ risulta $0,1133$, mentre per $k=12$ è $0,2277$. Quindi il nostro $k$ è compreso tra 11 e 12. In conclusione, se il nostro test dovesse presentare 12 (o più) successi, allora non rifiuteremmo $H_0$. In caso contrario scarteremmo $H_0$ a favore di $H_1$.

\begin{definizione} Sia $\beta := P(\underline{x} \in C_0 \mid \theta \in \Theta_1)$, ovvero $\beta$ è la probabilità (fissato $\alpha$) di commettere un errore di II specie. Chiamiamo \textit{potenza del test} il valore $\gamma := 1-\beta$. Un test risulta ottimale quando la sua potenza è massima. Notiamo che possiamo definire una \textit{funzione di potenza} $\gamma(t) := 1-\beta(t)$
\end{definizione}
\begin{oss} Prendendo di nuovo in considerazione l'esempio precedente sul campione casuale normale, è chiaro che una volta fissato $\alpha$, ovvero $c$, minore è $\mu_1$, più piccola è l'area sottesa dalla coda della relativa normale, ovvero $\beta$.
\end{oss}
\noindent \textbf{Esempio} Prendendo di nuovo in considerazione l'esempio precedente sulla bernoulliana, abbiamo che 
			$$\gamma(p) = P(S \leq k \mid p<p_0) = \displaystyle \sum_{s=0}^k \binom{n}{s} p^s (1-p)^{n-s}$$
Di seguito possiamo osservare il grafico della funzione:\\
\\
INSERIRE GRAFICO\\
\\
\textbf{Osservazione} Il test in merito al precedente sistema di ipotesi relative a $p$ è un \textit{test esatto}, perché poggia sulla distribuzione \textit{esatta} di $S$ ($S \sim b(n,p)$). Questo però non accade sempre, e quindi talvolta è necessario ricorrere alla teoria asintotica e dei test approssimati.\\
???DISCORSO SU IPOTESI SEMPLICI E COMPOSTE DA CAPIRE MEGLIO\\
\\
\\
\subsection{Esempi di statistiche test (generali e particolari)}

\textbf{Test per la media di una popolazione qualsiasi} Supponiamo di avere un campione casuale $(X_1,...,X_n)$ proveniente da una distribuzione \underline{non} nota di media $\mu$ e varianza $\sigma^2$ (finita) \underline{non} note.\\
Le nostre ipotesi sono 
$$\bigg \{
\begin{array}{rl}
H_0: & \mu=\mu_0 \\
H_1: & \mu>\mu_0 \\
\end{array}
$$
Decidiamo di ''condensare'' l'informazione presente nel campione circa $\mu$ e $\sigma^2$ tramite $\overline{X}_n$ e $S_n^2$ (che ricordiamo essere stimatori non distorti e consistenti), sapendo che $\overline{X}_n \stackrel{P}{\rightarrow} \mu$ e $S_n^2 \stackrel{P}{\rightarrow} \sigma^2$.\\
A questo punto, la nostra regola di decisione consisterà nel rifiutare $H_0$ a favore di $H_1$ se $\overline{X}_n$ è molto più grande di $\mu_0$.\\
Noi sappiamo che $\overline{X}_n \stackrel{a}{\sim} N(\mu, \frac{S_n^2}{n}$, ovvero $\frac{\overline{X}_n-\mu}{S_n/\sqrt{n}} \stackrel{D}{\rightarrow} N(0,1) =: Z$\\
Usando questo risultato possiamo individuare la regione critica del test di livello $\alpha$ fissato. Imponiamo la seguente uguaglianza:

\begin{eqnarray}
\alpha 	&=& P(\overline{x} \in C \mid \mu=\mu_0) = P(\overline{X}_n \geq k \mid \mu=\mu_0) \nonumber \\
		&=& P \left( \frac{\overline{X}_n-\mu}{S_n/\sqrt{n}} \geq \frac{\overline{k}-\mu}{S_n/\sqrt{n}} \mid \mu=\mu_0 \right) \nonumber \\
		&=& P \left( \frac{\overline{X}_n-\mu_0}{S_n/\sqrt{n}} \geq \frac{\overline{k}-\mu_0}{S_n/\sqrt{n}} \right) = P(Z \geq z_{\alpha}) \nonumber
\end{eqnarray}

Dove $z_{\alpha}$ è il valore da cercare sulle tavole relative alla distribuzione normale in funzione dell'$\alpha$ scelto. Nota: l'ultima uguaglianza è in realtà un'approssimazione che è tanto più corretta quanto più grande è $n$.\\
In definitiva, abbiamo che $C = \lbrace \underline{x} \in \varkappa \; : \; \frac{\overline{X}_n-\mu_0}{S_n/\sqrt{n}} \geq z_{\alpha} \rbrace = \lbrace \underline{x} \in \varkappa \; : \; \overline{X}_n \geq \mu_0 + z_{\alpha} \frac{S}{\sqrt{n}} \rbrace$\\

Possiamo anche considerare la \textit{funzione di potenza approssimata}:

\begin{eqnarray}
\gamma(\mu) = 1- \beta(\mu) 	&=& P(\overline{X}_n \geq \mu_0 + z_{\alpha} \sigma / \sqrt{n} \mid \mu > \mu_0) \nonumber \\
							&=& P \left(\frac{\overline{X}_n-\mu}{\sigma / \sqrt{n}} \geq \frac{\mu_0 + z_{\alpha} \sigma / \sqrt{n} - \mu}{\sigma / \sqrt{n}} \right) \nonumber \\
							&=& 1-P \left( Z \geq z_{\alpha} + \frac{\sqrt{n}(\mu_0 - \mu)}{\sigma} \right) \nonumber \\
							&=& 1-\Phi \left( z_{\alpha} + \frac{\sqrt{n}(\mu_0 - \mu)}{\sigma} \right) \nonumber
\end{eqnarray}

dove $\Phi$ è la funzione di ripartizione di $N(0,1)$.\\
Notiamo che il valore di $\gamma(\mu)$ tende a 1 per $n \rightarrow \infty$. Intuitivamente, questo è esattamente ciò che ci aspettiamo, in quanto più è grande $\mu$, più esso è distante dal nostro $\mu_0$, e di conseguenza è lecito aspettarsi che la probabilità che un campione abbia media vicina a $\mu$ sarà bassa, ovvero la potenza del test è elevata.\\
È chiaro quindi che una funzione di potenza è tanto migliore quanto più il suo grafico sta vicino alla retta $y=1$.\\
\\
\textbf{Esempio} In riferimento al caso generale appena trattato, supponiamo di avere $\mu_0=12$, $\overline{X}_n=14,3$, $S_n^2=22,5$, $n=50$. Se fissiamo $\alpha=0,05$, usando le tavole per la distribuzione normale $N(0,1)$ troviamo $z_{\alpha}=1,645$. Ne segue che $k=12+1,645\sqrt{22,5/50}$, che è minore di $14,3$. Concludiamo quindi rifiutando $H_0$.\\
\\
\textbf{Esempio di test esatto con t di Student} Abbiamo $(X_1,...,X_n)$ campione casuale da $N(\mu,\sigma^2)$ con $\mu$ e $\sigma^2$ non noti. Le nostre ipotesi sono:
$$\bigg \{
\begin{array}{rl}
H_0: & \mu=\mu_0 \\
H_1: & \mu>\mu_0 \\
\end{array}
$$
Sappiamo che $\overline{X}_n \stackrel{H_0}{\sim} N(\mu_0,\sigma^2/n)$ e quindi:
$$T:= \frac{\overline{X}_n - \mu_0}{S_n / \sqrt{n}} = \frac{\overline{X}_n - \mu_0}{\sigma / \sqrt{n}} \frac{1}{\sqrt{S_n^2 / \sigma^2}} \sim \frac{Z}{S_n / \sqrt{n}} \sim t_{n-1}$$
(vedi pag. 17 e pag. 12)\\
A questo punto, possiamo trovare il nostro valore critico $k$ usando le tavole della distribuzione $t_{n-1}$.\\
Notiamo che quello appena mostrato è un \textit{test esatto}, in quanto non si basa su un'approssimazione dello stimatore per valori elevati di $n$ (usando ad esempio il TLC), bensì usa la sua distribuzione reale (in questo caso la distribuzione $t_{n-1}$).

\textbf{Esempio di test t-Student per due campioni}\\
Campione $(X_1,...,X_{n_1})$ da $N(\mu_1,\sigma^2)$ e $(Y_1,...,Y_{n_2})$ da $N(\mu_2,\sigma^2)$ indipendenti. La varianza $\sigma$ è la stessa ma non è nota.\\
Supponiamo di avere elementi per pensare che:
$$\bigg \{
\begin{array}{rl}
H_0: & \mu_1=\mu_2 \\
H_1: & \mu_1>\mu_2 \\
\end{array}
$$
Abbiamo che $\overline{X}_1 - \overline{X}_2 \sim N(\mu_1 - \mu_2, \sigma_1/n_1 + \sigma_2/n_2)$.\\
Prendiamo ora 
$$S_p^2:= \frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n-2}$$ 
dove $n=n_1+n_2$.\\
Abbiamo che:
$$T:= \frac{(\overline{X}_1 - \overline{X}_2)-(\mu_1-\mu_2)}{S_p \sqrt{1/n_1+1/n_2}} \; \stackrel{H_0}{\sim} \; t_{n-2}$$
dove abbiamo usato anche il fatto che $S_p^2$ è una chi-quadro con $n-2$ gradi di libertà (vedi pag. 19).\\
In conclusione, avremo che la nostra regione critica sarà $C=\lbrace (\underline{x},\underline{y}) \mid T \geq t_{n-2;\alpha} \rbrace$.\\
\\
\textbf{Esempio con bernoulliana} Abbiamo $(X_1,...,X_n)$ campione casuale da $b(1,p)$ (ricordiamo: media $p$, varianza $p(1-p)$). Le nostre ipotesi sono:
$$\bigg \{
\begin{array}{rl}
H_0: & p=p_0 \\
H_1: & p=p_1 \\
\end{array}
$$
con $p_1<p_0$. Consideriamo
$$\hat{p}_n := \frac{\sum X_i}{n} \stackrel{a}{\sim} N \left( p, \frac{p(1-p)}{n} \right)$$
Abbiamo quindi:
$$Z:= \frac{\hat{p}_n-p_0}{\sqrt{\frac{\hat{p}_n (1-\hat{p}_n)}{n}}}$$
A questo punto imponiamo: $\alpha = P(Z \leq z_{\alpha} \mid H_0)$.\\
\\
\textbf{Esempio di test sulla varianza} Campione casuale $(X_1,...,X_n)$ da $N(\mu,\sigma^2)$, $\mu$ e $\sigma^2$ non noti. Le nostre ipotesi sono: 
$$\bigg \{
\begin{array}{rl}
H_0: & \sigma^2=\sigma_0^2 \\
H_1: & \sigma^2=\sigma_1^2 \\
\end{array}
$$
con $\sigma_1^2 > \sigma_0^2$.
Notiamo che $\frac{n-1}{\sigma_0^2} S_n^2 \stackrel{H_0}{\sim} \chi_{n-1}^2 =: W$. (Nota: come in molti esempi precedenti, il fatto che sia "intelligente" tirare fuori queste osservazioni che portano all'analisi di distribuzioni conosciute è "calato dall'alto", almeno per ora).\\
Imponiamo:
$$\alpha = P \left( \frac{n-1}{\sigma^2} S_n^2 \mid \sigma^2=\sigma_0^2 \right) = P \left( \frac{n-1}{\sigma_0^2} S_n^2 \right)$$
Quindi $k=w_{\alpha;n-1}$. In conclusione, rifiuto $H_0$ se $W \geq w_{\alpha;n-1}$.\\
\textbf{Esempio} In riferimento al caso generale appena trattato, supponiamo di avere $n=25$, $\sigma_0^2=15$, $\sigma_1^2=20$, $s_n^2=17,4$ e $\alpha=0,05$. Allora:
$$k=w_{0,05;(25-1)} = w_{0,05;24} = 36,415 > 27,84 = \frac{25-1}{15} 17,4 = \frac{n-1}{\sigma_0^2} s_n^2 = w$$
In conclusione, non rifiutiamo $H_0$.\\
\\
\textbf{Esempio con due campioni normali} Campione $(X_1,...,X_{n_1})$ da $N(\mu_1,\sigma_1^2)$ e $(Y_1,...,Y_{n_2})$ da $N(\mu_2,\sigma_2^2)$ indipendenti. $\mu_i$ e $\sigma_i^2$ non noti. Le nostre ipotesi sono:
$$\bigg \{
\begin{array}{rl}
H_0: & \sigma_1^2=\sigma_2^2 \\
H_1: & \sigma_1^2 \neq \sigma_2^2 \\
\end{array}
$$
Nota: l'ipotesi dell'uguaglianza delle due varianze prende il nome di omoschedasticità.\\
Sappiamo che $S_i^2 \stackrel{P}{\rightarrow} \sigma_i^2$. Inoltre
$$W:= \frac{S_2^2 / \sigma_2^2}{S_1^2 / \sigma_1^2} = 
\frac{\frac{(n_2-1) S_2^2}{\sigma_2^2} \frac{1}{n_2-1}} {\frac{(n_1-1) S_1^2}{\sigma_1^2} \frac{1}{n_1-1}} 
\sim F_{(n_2-1),(n_1-1)}$$
(vedi pag. 20)\\
Sotto $H_0$ abbiamo chiaramente che $W:= \frac{S_2^2 / \sigma_2^2}{S_1^2 / \sigma_1^2} = \frac{S_2^2}{S_1^2}$. La nostra regola di decisione consisterà nel rifiutare $H_0$ a favore di $H_1$ se $\frac{S_2^2}{S_1^2}$ è ''lontano'' da 1, ovvero se $W<k_1$ o $W>k_2$, dove $k_1$ e $k_2$ dipendono dalla distribuzione di $W= \frac{S_2^2}{S_1^2}$ e dal valore di $\alpha$. Perciò, dividendo equamente in due parti la probabilità di errore, le due equazioni risultano:
$$\alpha/2 = P(W>k_2 \mid \sigma_1^2=\sigma_2^2) \; \; \text{ e } \; \; 1-\alpha/2 = P(W<k_1 \mid \sigma_1^2=\sigma_2^2)$$
In conclusione, 
$$C= \lbrace (\underline{x_1},\underline{x_2}) \; : \; \frac{S_2^2}{S_1^2} < w_{(n_2-1),(n_1-1);\alpha/2} \; \; \text{ o } \; \; \frac{S_2^2}{S_1^2} > w_{(n_2-1),(n_1-1);1-\alpha/2}$$
In riferimento al caso generale appena trattato, supponiamo di avere $n_1=14$, $n_2=10$ $s_1^2=17,4$, $\sigma_1^2=20$, $s_2^2=37,9$ e $\alpha=0,05$.\\
Come nel caso generale, diciamo $W:=S_2^2/S_1^2 \sim F_{(n_2-1),(n_1-1)}$.\\
Abbiamo che $w_{(10-1),(14-1);0,025}=3,31$ e $w_{(10-1),(14-1);0,975}=1/w_{13,19;0,025}=1/3,76=0,26$.\\
Poiché $s_2^2/s_1^2=37,9/17,4=2,178$, decidiamo di non rifiutare $H_0$.